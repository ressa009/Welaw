from asyncgpt.asyncgpt.chatgpt import GPT
import asyncio, httpx, tempfile, os, re, openai, aiosmtplib
from transformers import GPT2Tokenizer
from quart import jsonify
from PyPDF2 import PdfReader
from email.mime.text import MIMEText
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
from network_utils import send_response
import numpy as np
import pandas as pd
from chatbot_db import DBManager
from typing import List, Dict
from langchain.schema import AgentAction
from langchain.tools import Tool
from langchain.prompts import StringPromptTemplate

load_dotenv()
bot = GPT(apikey=os.getenv('GPT_API_KEY'))


# DB ì—°ê²°
db = DBManager(
    host=os.getenv('DB_HOST'),
    port=int(os.getenv('DB_PORT')),
    user=os.getenv('DB_USER'),
    password=os.getenv('DB_PASSWORD'),
    db=os.getenv('DB_NAME')
)


summary = None #ì „ì—­ë³€ìˆ˜ summary ì¶”ê°€

workspace_path = os.getcwd()
REPOSITORY_PATH = os.path.join(workspace_path, "playground")

embeddings_file_path = os.path.join(REPOSITORY_PATH, 'case_embeddings.npy')
indices_file_path = os.path.join(REPOSITORY_PATH, 'case_indices.npy')

embeddings = np.load(embeddings_file_path).astype('float32')
indices = np.load(indices_file_path)

case_data = pd.read_csv(os.path.join(REPOSITORY_PATH, 'cases.csv'))
sessions = {}
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

async def send_email(recipient, subject, body):
    # ì´ë©”ì¼ ì„¤ì •
    sender = os.getenv('EMAIL_ID')
    password = os.getenv('EMAIL_PW')
    message = MIMEText(body)
    message['Subject'] = subject
    message['From'] = sender
    message['To'] = recipient

    # ì´ë©”ì¼ ë³´ë‚´ê¸°
    smtp = aiosmtplib.SMTP(hostname="smtp.gmail.com", port=465, use_tls=True)
    await smtp.connect()
    await smtp.login(sender, password)
    await smtp.send_message(message)
    await smtp.quit()


def get_ada_embedding(text):
    return openai.Embedding.create(model="text-embedding-ada-002", input=text)["data"][0]["embedding"]


def split_into_chunks(text, max_length):
    """Split the text into chunks that are at most max_length characters long."""
    chunks = []
    current_chunk = ""
    for sentence in text.split("."):
        new_chunk = (current_chunk + " " + sentence.strip()).strip()
        if len(new_chunk) > max_length:
            chunks.append(current_chunk)
            current_chunk = sentence
        else:
            current_chunk = new_chunk
    chunks.append(current_chunk)
    return chunks


async def summarize_chunk(chunk):
    completion = await bot.chat_complete([{"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ í•œê¸€ë¡œ ìš”ì•½í•´ì¤˜.: {chunk}"}])
    return completion.choices[0].message['content']


async def download_and_summarize_pdf(url):
    global summary  # summaryë¥¼ ì „ì—­ë³€ìˆ˜ë¡œ ì„¤ì •

    # PDF íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
    response.raise_for_status()  # ì‘ë‹µ ì„±ê³µ ë³´ì¥

    # ì„ì‹œ íŒŒì¼ ìƒì„±
    temp_file = tempfile.NamedTemporaryFile(delete=False)

    # ë‚´ë ¤ë°›ì€ ë‚´ìš©ì„ ì„ì‹œ íŒŒì¼ì— ì €ì¥
    with open(temp_file.name, "wb") as f:
        f.write(response.content)

    # PyPDF2ë¡œ PDF íŒŒì¼ ì½ê¸°
    pdf_reader = PdfReader(temp_file.name)

    # PDF ë‚´ìš© ì¶”ì¶œ
    text = " ".join([page.extract_text() for page in pdf_reader.pages])

    # í…ìŠ¤íŠ¸ë¥¼ 3500ìì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    chunks = split_into_chunks(text, 3500)

    # ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ ì‚¬ê±´ëª… ì°¾ê¸°
    prompts = [
        {"role": "user", "content": "íŒê²°ë¬¸ ì¼ë¶€: 'ëŒ€ë²•ì› 1969.2.4. ì„ ê³  68ë‹¤1587 íŒê²°\n1\nëŒ€ë²•ì› 1969.2.4.ì„ ê³  68ë‹¤1587 íŒê²°\nã€ì†Œìœ ê¶Œì´ì „ë“±ê¸°ë§ì†Œã€‘, [ì§‘17(1)ë¯¼,155]\nã€íŒì‹œì‚¬í•­ã€‘\nì‚¬í›„ì–‘ìëŠ” í˜¸ì£¼ìƒì†ê¶Œì€ ìˆì–´ë„ ì¬ì‚°ìƒì†ê¶Œì€ ì—†ë‹¤' ì‚¬ê±´ëª…: "},
        {"role": "assistant", "content": "ì†Œìœ ê¶Œì´ì „ë“±ê¸°ë§ì†Œ"},
        {"role": "user", "content": "íŒê²°ë¬¸ ì¼ë¶€: 'ì„œ ìš¸ ì¤‘ ì•™ ì§€ ë°© ë²• ì› \níŒ ê²°\nì‚¬ ê±´ 2009ê³ ë‹¨3458 ê°€. ëª…ì˜ˆí›¼ì† \n ë‚˜. ì—…ë¬´ë°©í•´\n í”¼ ê³  ì¸ 1.ê°€.ë‚˜. ì¡°00 (610619-1000000), MBC í”„ë¡œë“€ì„œ \n ì£¼ê±° ì„œìš¸ 000\n ë“±ë¡ê¸°ì¤€ì§€ ì„œì‚°ì‹œ000' ì‚¬ê±´ëª…: "},
        {"role": "assistant", "content": "ëª…ì˜ˆí›¼ì† ë° ì—…ë¬´ë°©í•´"},
        {"role": "user", "content": "íŒê²°ë¬¸ ì¼ë¶€: 'ëŒ€ë²•ì› 2018. 4. 12.ì„ ê³  2017ë‹¤292244 íŒê²° ã€ì†Œìœ ê¶Œí™•ì¸ã€‘, [ê³µ2018ìƒ,897] ã€íŒì‹œì‚¬í•­ã€‘ [1] ë¶€ë™ì‚° ë§¤' ì‚¬ê±´ëª…: "},
        {"role": "assistant", "content": "ì†Œìœ ê¶Œí™•ì¸"},
        {"role": "user", "content": f"íŒê²°ë¬¸ ì¼ë¶€: {chunks[0]} ì‚¬ê±´ëª… : "}
    ]
    case_name_completion = await bot.chat_complete(prompts)
    case_name = case_name_completion.choices[0].message['content']

    tasks = [summarize_chunk(chunk) for chunk in chunks]
    summaries = await asyncio.gather(*tasks)       
    # ìš”ì•½ëœ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    summary = " ".join(summaries)

    # Remove the temporary file
    os.remove(temp_file.name)
         
    # ì‚¬ê±´ëª…ê³¼ ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
    return case_name, summary


def find_related_cases(query_embedding):
    k = 2
    query_embedding_np = np.array(query_embedding)  # ë¦¬ìŠ¤íŠ¸ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜

    # íŒê²° ìš”ì§€ì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    judgement_indices = case_data['íŒê²°ìš”ì§€'].index

    # ì„ë² ë”© ë°°ì—´ì˜ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    valid_indices = judgement_indices[judgement_indices < len(embeddings)]

    # íŒê²° ìš”ì§€ì˜ ì„ë² ë”©ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    judgement_embeddings = embeddings[valid_indices]

    # íŒê²° ìš”ì§€ì˜ ì„ë² ë”©ë§Œì„ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    similarities = cosine_similarity(judgement_embeddings, query_embedding_np.reshape(1, -1))
    top_k_indices = similarities.flatten().argsort()[-k:][::-1]

    top_k_rows = [case_data.iloc[indices[idx]] for idx in top_k_indices]

    return top_k_rows


async def send_related_cases_email(recipient_email, related_cases):
    email_body = ""
    for case in related_cases:
        email_body += f"ã€íŒë¡€ì¼ë ¨ë²ˆí˜¸ã€‘: {case['íŒë¡€ì¼ë ¨ë²ˆí˜¸']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€ì‚¬ê±´ëª…ã€‘: {case['ì‚¬ê±´ëª…']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€ì‚¬ê±´ë²ˆí˜¸ã€‘: {case['ì‚¬ê±´ë²ˆí˜¸']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€ì‚¬ê±´ì¢…ë¥˜ëª…ã€‘: {case['ì‚¬ê±´ì¢…ë¥˜ëª…']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€íŒì‹œì‚¬í•­ã€‘: {case['íŒì‹œì‚¬í•­']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€íŒê²°ìš”ì§€ã€‘: {case['íŒê²°ìš”ì§€']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€ì°¸ì¡° ì¡°ë¬¸ã€‘: {case['ì°¸ì¡°ì¡°ë¬¸']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€ì°¸ì¡° íŒë¡€ã€‘: {case['ì°¸ì¡°íŒë¡€']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"
        email_body += f"ã€íŒë¡€ë‚´ìš©ã€‘: {case['íŒë¡€ë‚´ìš©']}\n"
        email_body += "\n"
        email_body += "--------------------------------\n"
        email_body += "\n"

    # ì´ë©”ì¼ ë³´ë‚´ê¸°
    await send_email(recipient_email, 'Related Cases', email_body)

def find_most_similar_case(query_embedding: np.array, embeddings: np.array) -> Dict:
    most_similar_index = np.argmax(np.dot(query_embedding, embeddings.T))
    case_id = indices[most_similar_index]
    case = case_data.iloc[case_id]
    return case

# def find_most_similar_case(query_embedding: np.array, embeddings: np.array, top_n=5, threshold=0.7) -> Dict:
#     # Calculate similarity scores
#     scores = np.dot(query_embedding, embeddings.T)
    
#     # Get the top N most similar cases
#     top_indices = np.argsort(scores)[-top_n:]
    
#     # Filter out cases with similarity below the threshold
#     top_indices = [idx for idx in top_indices if scores[idx] >= threshold]
    
#     # If no cases meet the threshold, return the most similar one
#     if not top_indices:
#         top_indices = [np.argmax(scores)]
    
#     # Choose one randomly from the top N
#     chosen_index = np.random.choice(top_indices)
    
#     case_id = indices[chosen_index]
#     case = case_data.iloc[case_id]
#     return case

def case_retrieval_func(input):
    # Convert the input to embeddings
    query_embedding = get_embedding(input)
    # Find the most similar case
    case = find_most_similar_case(query_embedding, embeddings)
    return case

tools = [Tool(name="Case Retrieval", description="Retrieve similar cases from the database using embeddings.", func=case_retrieval_func)]

class CustomPromptTemplate(StringPromptTemplate):
    # The template to use
    template: str
    # The list of tools available
    tools: List[Tool]
    input_variables: List[str]

    def format(self, **kwargs) -> str:
        # Get the intermediate steps (AgentAction, Observation tuples)
        # Format them in a particular way
        intermediate_steps = kwargs.pop("intermediate_steps", [])
        thoughts = ""
        for action, observation in intermediate_steps:
            thoughts += action.log
            thoughts += f"\nObservation: {observation}\nThought: "
        # Set the agent_scratchpad variable to that value
        kwargs["agent_scratchpad"] = thoughts
        # Create a tools variable from the list of tools provided
        kwargs["tools"] = "\n".join([f"{tool.name}: {tool.description}" for tool in self.tools])
        # Create a list of tool names for the tools provided
        kwargs["tool_names"] = ", ".join([tool.name for tool in self.tools])
        return self.template.format(**kwargs)    

def get_embedding(question: str) -> np.array:
    return get_ada_embedding(question)

async def get_answer(user_utterance, callback_url, session_id):
    global summary  # declare summary as global inside the function

    case_name = ""

    if session_id in sessions:
        messages = sessions[session_id]
    else:
        messages = []

    messages.append({"role": "user", "content": user_utterance})
    tokens = tokenizer.encode(str(messages))
    if len(tokens) >= 6500 or len(messages) > 20:
        messages.pop(0)
        if len(tokens) >= 7500:
            messages.pop(0)
    
    elif user_utterance.startswith('ì§ˆë¬¸'):
        prompts = [{"role": "user", "content": f"{summary}ë¥¼ ë°”íƒ•ìœ¼ë¡œ {user_utterance}ì— ëŒ€í•´ ë‹µë³€í•´ì¤˜"},]
        print(prompts)
        completion = await bot.chat_complete(prompts)
        answer = str(completion)
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "action": "message",
                        "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                        "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                    },
                    {
                        "action": "message",
                        "label": "ì„œìˆ ìƒë‹´ì´ì–´ê°€ê¸°",
                        "messageText": "ğŸ“„ ì„œìˆ  ìƒë‹´"
                    }
                ]
            }
        }

    elif user_utterance.startswith('ì°¾ê¸°'):
        # 'ìƒë‹´' ë’¤ì— ì˜¤ëŠ” í…ìŠ¤íŠ¸ë¥¼ summaryì— ì €ì¥
        summary = user_utterance[2:]

        # ìœ ì‚¬í•œ íŒë¡€ ì°¾ê¸°
        query_embedding = get_embedding(summary)
        case = find_most_similar_case(query_embedding, embeddings)

        # í•´ë‹¹ íŒë¡€ì˜ ìš”ì•½ì„ AgentActionìœ¼ë¡œ ìƒì„±
        agent_action = AgentAction("Case Retrieval", "", 
            f"ë¹„ìŠ·í•œ íŒë¡€ë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\níŒë¡€ì¼ë ¨ë²ˆí˜¸ : {case['íŒë¡€ì¼ë ¨ë²ˆí˜¸']}\nì‚¬ê±´ëª… : {case['ì‚¬ê±´ëª…']}\níŒê²°ìš”ì§€ : \n{case['íŒê²°ìš”ì§€']}")

        template = """Answer the following questions as best you can. You have access to the following tools:

        {tools}

        Use the following format:

        Question: {input}
        Thought: 
        Action: the action to take, should be one of [{tool_names}]
        Action Input: 
        Observation: 
        ... (this Thought/Action/Action Input/Observation can repeat N times)
        Thought: I now know the final answer
        Final Answer: 

        Begin! 

        {agent_scratchpad}
        """

        # Create the prompt template
        prompt = CustomPromptTemplate(
            template=template,
            tools=tools,
            input_variables=["input", "intermediate_steps"]
        )

        # Fill the template with the case data
        filled_template = prompt.format(
            input=summary,
            intermediate_steps=[
                (agent_action, "End of process"),
                # Add more steps as needed
            ]
        )
        summary = filled_template.split('Begin!')[-1].split('Observation:')[0].strip()
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": filled_template.split('Begin!')[-1].split('Observation:')[0].strip() # ìˆ˜ì •ëœ ë¶€ë¶„
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "action": "message",
                        "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                        "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                    },
                    {
                        "action": "message",
                        "label": "ìƒë‹´ ì´ì–´ê°€ê¸°",
                        "messageText": "ğŸ“ƒ ì„œìˆ  ìƒë‹´"
                    }
                ]
            }
        }
    elif user_utterance == "ğŸ“¥PDF ì—…ë¡œë“œ":
        answer = "ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ https://www.file.io/ pdfíŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”. ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´ ìƒì„±ëœ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. 1ë¶„ì •ë„ ì†Œìš”ê°€ ë©ë‹ˆë‹¤."
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    },
                    {
                        "basicCard": {
                            "buttons": [
                                {
                                    "action": "webLink",
                                    "label": "Go to file.io",
                                    "webLinkUrl": "https://www.file.io/"}]}}]}}
    elif user_utterance.startswith('url :') or user_utterance.startswith('https://file.io/'):
        if user_utterance.startswith('url :'):
            url = user_utterance[5:]
        else:
            url = user_utterance
        case_name, summary = await download_and_summarize_pdf(url)
        answer = f"ì˜¬ë ¤ì£¼ì‹  PDFì˜ ìš”ì•½ë³¸ì…ë‹ˆë‹¤.\nì‚¬ê±´ëª…: {case_name}\nìš”ì•½: {summary}"
        response = {
            "version": "2.0",
              "template": {
                "outputs": [
                  {
                    "simpleText": {
                      "text": answer
                    }
                  }
                ],
                "quickReplies": [
                  {
                    "messageText": "ìœ ì‚¬í•œ íŒë¡€ ì´ë©”ì¼ ë°›ê¸°",
                    "action": "message",
                    "label": "ìœ ì‚¬í•œ íŒë¡€ ë°›ê¸°"
                  },
                  {
                    "messageText": "ìœ ì‚¬í•œ íŒë¡€ ì´ë©”ì¼ ì•ˆ ë°›ê¸°",
                    "action": "message",
                    "label": "ìœ ì‚¬í•œ íŒë¡€ ì•ˆ ë°›ê¸°"
                  }
                ]
              }
            }

    elif user_utterance == "ìœ ì‚¬í•œ íŒë¡€ ì´ë©”ì¼ ë°›ê¸°":
        recipient_email = await db.get_email_address(session_id)
        print(recipient_email)
        if recipient_email:
            answer = f"{recipient_email}, ì´ ì£¼ì†Œë¡œ ì´ë©”ì¼ì„ ë³´ë‚´ë“œë¦´ê¹Œìš”?"
            response = {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {
                            "simpleText": {
                                "text": answer
                            }
                        }
                    ],
                    "quickReplies": [
                        {
                            "messageText": "ë„¤, ì´ë©”ì¼ ì£¼ì†Œê°€ ë§ìŠµë‹ˆë‹¤.",
                            "action": "message",
                            "label": "ë„¤, ì´ë©”ì¼ ì£¼ì†Œê°€ ë§ìŠµë‹ˆë‹¤."
                        },
                        {
                            "messageText": "ì•„ë‹ˆìš”, ì´ë©”ì¼ ì£¼ì†Œê°€ í‹€ë¦½ë‹ˆë‹¤.",
                            "action": "message",
                            "label": "ì•„ë‹ˆìš”, ì´ë©”ì¼ ì£¼ì†Œê°€ í‹€ë¦½ë‹ˆë‹¤."
                        }
                    ]
                }
            }
        else:
            answer = "ì‚¬ìš©ì IDì— ì—°ê²°ëœ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \n ë°›ìœ¼ë ¤ëŠ” ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” \n ex) amugae@test.com"
            response = {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {
                            "simpleText": {
                                "text": answer
                            }
                        }
                    ]
                }
            }

    elif user_utterance == "ë„¤, ì´ë©”ì¼ ì£¼ì†Œê°€ ë§ìŠµë‹ˆë‹¤.":
        summary_embedding = get_ada_embedding(summary)  # ìš”ì•½ëœ íŒë¡€ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±
        related_cases = find_related_cases(summary_embedding)
        recipient_email = await db.get_email_address(session_id)
        asyncio.create_task(send_related_cases_email(recipient_email, related_cases))

        answer = "ìœ ì‚¬í•œ íŒë¡€ ì •ë³´ë¥¼ ì´ë©”ì¼ë¡œ ë³´ë‚´ë“œë ¸ìŠµë‹ˆë‹¤."
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "action": "message",
                        "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                        "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                    },
                    {
                        "action": "message",
                        "label": "PDF ê´€ë ¨ ìƒë‹´í•˜ê¸°",
                        "messageText": "ğŸ“„ ì„œìˆ  ìƒë‹´"
                    }
                ]
            }
        }

    elif user_utterance == "ì•„ë‹ˆìš”, ì´ë©”ì¼ ì£¼ì†Œê°€ í‹€ë¦½ë‹ˆë‹¤.":
        answer = "ì´ë©”ì¼ì„ ë°›ìœ¼ë ¤ëŠ” ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    }
                ]
            }
        }
    # elif user_utterance == "ğŸ”íŒë¡€ê²€ìƒ‰":
    #     response = {
    #         "version": "2.0",
    #         "template": {
    #             "outputs": [
    #                 {
    #                     "simpleText": {
    #                         "text": "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ìƒë‹´ì„ ì›í•˜ì‹œë‚˜ìš”?"}}],
    #             "quickReplies": [
    #                 {
    #                     "label": "PDFë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤",
    #                     "action": "message",
    #                     "messageText": "ğŸ“¥PDF ì—…ë¡œë“œ"
    #                 },
    #                 {
    #                     "label": "ì§ì ‘ì…ë ¥í•©ë‹ˆë‹¤",
    #                     "action": "message",
    #                     "messageText": "ğŸ”ì§ì ‘ì…ë ¥"}]}}
    elif user_utterance == "ìœ ì‚¬í•œ íŒë¡€ ì´ë©”ì¼ ì•ˆ ë°›ê¸°":
        answer = "ì´ë©”ì¼ì„ ë°›ì§€ ì•ŠëŠ” ê²ƒì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤."
        response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    }
                ],
                "quickReplies": [
                    {
                        "action": "message",
                        "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                        "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                    },
                    {
                        "action": "message",
                        "label": "PDF ê´€ë ¨ ìƒë‹´í•˜ê¸°",
                        "messageText": "ğŸ“„ ì„œìˆ  ìƒë‹´"
                    }
                ]
            }
        }

    # elif user_utterance == "ğŸ”ì§ì ‘ì…ë ¥": 
    #     answer = "'ì°¾ê¸° :'ì˜ ë’¤ì— íŒë¡€ì°¾ê¸°ì— í•„ìš”í•œ ë‚´ìš©ì„ ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì„œìˆ í•´ì£¼ì„¸ìš”. ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."
    #     response = {
    #         "version": "2.0",
    #         "template": {
    #             "outputs": [
    #                 {
    #                     "simpleText": {
    #                         "text": answer
    #                     }
    #                 }
    #             ]
    #         }
    #     }

    else:
        # ì´ë©”ì¼ ì£¼ì†Œ íŒ¨í„´ ê²€ìƒ‰
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        email_match = re.search(email_pattern, user_utterance)
        if email_match:
            recipient_email = email_match.group()
            print(summary)
            summary_embedding = get_ada_embedding(summary)  # ìš”ì•½ëœ íŒë¡€ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±
            related_cases = find_related_cases(summary_embedding)
            #case_name_cases = case_data[case_data['ì‚¬ê±´ëª…'].str.contains(case_name, na=False)]

            asyncio.create_task(send_related_cases_email(recipient_email, related_cases))

            answer = "ê´€ë ¨ íŒë¡€ ì •ë³´ë¥¼ ì´ë©”ì¼ë¡œ ë³´ë‚´ë“œë ¸ìŠµë‹ˆë‹¤."
            response = {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {
                            "simpleText": {
                                "text": answer
                            }
                        }
                    ],
                    "quickReplies": [
                        {
                            "action": "message",
                            "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                            "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                        },
                        {
                            "action": "message",
                            "label": "PDF ê´€ë ¨ ìƒë‹´ ì´ì–´ê°€ê¸°",
                            "messageText": "ğŸ“„ ì„œìˆ  ìƒë‹´"
                        }
                    ]
                }
            }

        else:
            #sessions[session_id] = messages 
            prompts = [{"role": "user", "content": f"{summary}ë¥¼ ë°”íƒ•ìœ¼ë¡œ {user_utterance}ì— ëŒ€í•´ ë‹µë³€í•´ì¤˜"},]
            print(prompts)
            completion = await bot.chat_complete(prompts)
            answer = str(completion)
            messages.append({"role": "system", "content": answer})
            tokens = tokenizer.encode(str(messages))
            print(len(tokens))
            if len(tokens) >= 6500 or len(messages) > 20:
                messages.pop(0)

            response = {
                "version": "2.0",
                "template": {
                    "outputs": [
                        {
                            "simpleText": {
                                "text": answer
                            }
                        }
                    ],
                    "quickReplies": [
                        {
                            "action": "message",
                            "label": "ì„œë¹„ìŠ¤ì•ˆë‚´ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°",
                            "messageText": "ì„œë¹„ìŠ¤ ì•ˆë‚´"
                        },
                        {
                            "action": "message",
                            "label": "ì„œìˆ ìƒë‹´ì´ì–´ê°€ê¸°",
                            "messageText": "ğŸ“„ ì„œìˆ  ìƒë‹´"
                        }
                    ]
                }
            }



    await send_response(callback_url, response)


# ì»¨íŠ¸ë¡¤ëŸ¬ì—ì„œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜ë¡œ, ì‹œë‚˜ë¦¬ì˜¤ 2ë²ˆ
async def law_question(user_request):
    
    # í”ŒëŸ¬ìŠ¤ì¹œêµ¬ì¸ì§€ í™•ì¸í•´ì„œ, ì¹œêµ¬ê°€ ì•„ë‹ˆë©´ ì¹œêµ¬ìš”ì²­ response
    if user_request.get('userRequest',{}).get('user',{}).get('properties',{}).get('isFriend') is not True:
        fail_response = {
            "version": "2.0",
            "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": "ì±„ë„ ì¶”ê°€ í›„ ì´ìš© ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    }
                }
            ]
            }
        }
        return jsonify(fail_response)

    user_id = user_request.get('userRequest', {}).get('user', {}).get('properties', {}).get('plusfriendUserKey', '')
    callback_url = user_request.get('userRequest', {}).get('callbackUrl')

    if user_request.get('action', {}).get('params', {}).get('summary_pdf'):
        user_utterance = user_request.get('action', {}).get('params', {}).get('summary_pdf')
    elif user_request.get('action', {}).get('params', {}).get('sys_url'):
        user_utterance = user_request.get('action', {}).get('detailParams', {}).get('sys_url',{}).get('origin')
    elif user_request.get('action', {}).get('params', {}).get('email_address'):
        user_utterance = user_request.get('action', {}).get('params', {}).get('email_address')
    # elif user_request.get('action', {}).get('params', {}).get('pdf_search'):
    #     user_utterance = user_request.get('action', {}).get('detailParams', {}).get('pdf_search',{}).get('origin')        
    else:
        user_utterance = user_request.get('userRequest', {}).get('utterance')
        print(user_utterance)
    
    if user_utterance == "ğŸ›ï¸ ë²•ë¥  ìƒë‹´":
        
        initial_response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ìƒë‹´ì„ ì›í•˜ì‹œë‚˜ìš”?"}}],
                "quickReplies": [
                    {
                        "label": "PDFë¡œìƒë‹´ë°›ê¸°",
                        "action": "message",
                        "messageText": "ğŸ“¥PDF ì—…ë¡œë“œ"
                    },
                    {
                        "label": "ì§ì ‘ì…ë ¥í•˜ì—¬ìƒë‹´ë°›ê¸°",
                        "action": "message",
                        "messageText": "ğŸ”ì§ì ‘ì…ë ¥"}]}}

    else:
        
        asyncio.create_task(get_answer(user_utterance, callback_url, user_id))
        initial_response = {
            "version": "2.0",
            "useCallback": True,
        }

    return jsonify(initial_response)

async def search_question(user_request):
    
    # í”ŒëŸ¬ìŠ¤ì¹œêµ¬ì¸ì§€ í™•ì¸í•´ì„œ, ì¹œêµ¬ê°€ ì•„ë‹ˆë©´ ì¹œêµ¬ìš”ì²­ response
    if user_request.get('userRequest',{}).get('user',{}).get('properties',{}).get('isFriend') is not True:
        fail_response = {
            "version": "2.0",
            "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": "ì±„ë„ ì¶”ê°€ í›„ ì´ìš© ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                    }
                }
            ]
            }
        }
        return jsonify(fail_response)
    print(user_request)
    user_id = user_request.get('userRequest', {}).get('user', {}).get('properties', {}).get('plusfriendUserKey', '')
    callback_url = user_request.get('userRequest', {}).get('callbackUrl')
    user_utterance = user_request.get('action', {}).get('params', {}).get('search_pdf')
    print(user_utterance)


    if user_utterance == "ğŸ­ğŸ™ˆğŸ’ì§ì ‘ì…ë ¥": 
        answer = "'ì°¾ê¸° :'ì˜ ë’¤ì— íŒë¡€ì°¾ê¸°ì— í•„ìš”í•œ ë‚´ìš©ì„ ìµœëŒ€í•œ ìì„¸í•˜ê²Œ ì„œìˆ í•´ì£¼ì„¸ìš”. ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬í•œ íŒë¡€ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."
        initial_response = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": answer
                        }
                    }
                ]
            }
        }        

    else:
        asyncio.create_task(get_answer(user_utterance, callback_url, user_id))
        initial_response = {
            "version": "2.0",
            "useCallback": True,
        }

    return jsonify(initial_response)

